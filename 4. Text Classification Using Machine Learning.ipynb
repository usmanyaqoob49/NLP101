{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9280060-fcc6-4710-8e08-750366f000e6",
   "metadata": {},
   "source": [
    "So in this Notebook We will Apply Machine Learning Models on the pre-processed data of Imdb Dataset, to predict sentiment of the new review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19d81995-9d26-46f1-b6d1-f738b46a0d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "683b275f-e07a-42c5-9277-c23393868c4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>simle_words_tokens</th>\n",
       "      <th>nltk_word_tokenize</th>\n",
       "      <th>nltk_sentence_tokenize</th>\n",
       "      <th>porter_stemming</th>\n",
       "      <th>lemmitized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one    reviewers  mentioned   watching  1 oz e...</td>\n",
       "      <td>positive</td>\n",
       "      <td>['one', 'reviewers', 'mentioned', 'watching', ...</td>\n",
       "      <td>['one', 'reviewers', 'mentioned', 'watching', ...</td>\n",
       "      <td>['one    reviewers  mentioned   watching  1 oz...</td>\n",
       "      <td>one review mention watch 1 oz episod youll hoo...</td>\n",
       "      <td>one reviewer mentioned watching 1 oz episode y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wonderful little production  filming techniqu...</td>\n",
       "      <td>positive</td>\n",
       "      <td>['wonderful', 'little', 'production', 'filming...</td>\n",
       "      <td>['wonderful', 'little', 'production', 'filming...</td>\n",
       "      <td>[' wonderful little production  filming techni...</td>\n",
       "      <td>wonder littl product film techniqu unassum old...</td>\n",
       "      <td>wonderful little production filming technique ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>thought    wonderful way  spend time    hot s...</td>\n",
       "      <td>positive</td>\n",
       "      <td>['thought', 'wonderful', 'way', 'spend', 'time...</td>\n",
       "      <td>['thought', 'wonderful', 'way', 'spend', 'time...</td>\n",
       "      <td>[' thought    wonderful way  spend time    hot...</td>\n",
       "      <td>thought wonder way spend time hot summer weeke...</td>\n",
       "      <td>thought wonderful way spend time hot summer we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically theres  family   little boy jake thi...</td>\n",
       "      <td>negative</td>\n",
       "      <td>['basically', 'theres', 'family', 'little', 'b...</td>\n",
       "      <td>['basically', 'theres', 'family', 'little', 'b...</td>\n",
       "      <td>['basically theres  family   little boy jake t...</td>\n",
       "      <td>basic there famili littl boy jake think there ...</td>\n",
       "      <td>basically there family little boy jake think t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter matteis love   time  money   visually s...</td>\n",
       "      <td>positive</td>\n",
       "      <td>['petter', 'matteis', 'love', 'time', 'money',...</td>\n",
       "      <td>['petter', 'matteis', 'love', 'time', 'money',...</td>\n",
       "      <td>['petter matteis love   time  money   visually...</td>\n",
       "      <td>petter mattei love time money visual stun film...</td>\n",
       "      <td>petter matteis love time money visually stunni...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment  \\\n",
       "0  one    reviewers  mentioned   watching  1 oz e...  positive   \n",
       "1   wonderful little production  filming techniqu...  positive   \n",
       "2   thought    wonderful way  spend time    hot s...  positive   \n",
       "3  basically theres  family   little boy jake thi...  negative   \n",
       "4  petter matteis love   time  money   visually s...  positive   \n",
       "\n",
       "                                  simle_words_tokens  \\\n",
       "0  ['one', 'reviewers', 'mentioned', 'watching', ...   \n",
       "1  ['wonderful', 'little', 'production', 'filming...   \n",
       "2  ['thought', 'wonderful', 'way', 'spend', 'time...   \n",
       "3  ['basically', 'theres', 'family', 'little', 'b...   \n",
       "4  ['petter', 'matteis', 'love', 'time', 'money',...   \n",
       "\n",
       "                                  nltk_word_tokenize  \\\n",
       "0  ['one', 'reviewers', 'mentioned', 'watching', ...   \n",
       "1  ['wonderful', 'little', 'production', 'filming...   \n",
       "2  ['thought', 'wonderful', 'way', 'spend', 'time...   \n",
       "3  ['basically', 'theres', 'family', 'little', 'b...   \n",
       "4  ['petter', 'matteis', 'love', 'time', 'money',...   \n",
       "\n",
       "                              nltk_sentence_tokenize  \\\n",
       "0  ['one    reviewers  mentioned   watching  1 oz...   \n",
       "1  [' wonderful little production  filming techni...   \n",
       "2  [' thought    wonderful way  spend time    hot...   \n",
       "3  ['basically theres  family   little boy jake t...   \n",
       "4  ['petter matteis love   time  money   visually...   \n",
       "\n",
       "                                     porter_stemming  \\\n",
       "0  one review mention watch 1 oz episod youll hoo...   \n",
       "1  wonder littl product film techniqu unassum old...   \n",
       "2  thought wonder way spend time hot summer weeke...   \n",
       "3  basic there famili littl boy jake think there ...   \n",
       "4  petter mattei love time money visual stun film...   \n",
       "\n",
       "                                          lemmitized  \n",
       "0  one reviewer mentioned watching 1 oz episode y...  \n",
       "1  wonderful little production filming technique ...  \n",
       "2  thought wonderful way spend time hot summer we...  \n",
       "3  basically there family little boy jake think t...  \n",
       "4  petter matteis love time money visually stunni...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reading the processed dataset\n",
    "df= pd.read_csv('pre_processed.csv')\n",
    "df.drop('Unnamed: 0', axis=1, inplace= True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb7c4bb-5b3f-4558-9e94-4badaedadccd",
   "metadata": {},
   "source": [
    "## DataFrame Pre Processing:\n",
    "Text is preprocessed but we have to check for the Missing Values and Duplicate Values etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29fc2e24-55ce-4ecc-a10e-c41b6fb85831",
   "metadata": {},
   "source": [
    "**Checking for the Duplicate Rows in Dataset and Dropping them:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e41bdeb1-8ec0-4eae-96d7-44b7729dcc61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "422"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1b02e78-6335-40cf-bddf-30d3ba8a355c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db40b19-adec-47c8-aa26-ce52d570df08",
   "metadata": {},
   "source": [
    "**Checking for the Null Values:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "744084bc-fc53-4791-ba04-58c615d1990b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review                    0\n",
       "sentiment                 0\n",
       "simle_words_tokens        0\n",
       "nltk_word_tokenize        0\n",
       "nltk_sentence_tokenize    0\n",
       "porter_stemming           0\n",
       "lemmitized                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a9a8a6-a73c-4ee5-a7bb-e60c36ca4bd6",
   "metadata": {},
   "source": [
    "**Checking Class Balance:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35a7acfa-23f6-4cf6-bc4e-6eac8bc602f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "positive    24883\n",
       "negative    24695\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f987c2f8-1c68-43b1-9136-83a489513f91",
   "metadata": {},
   "source": [
    "Class balance looks pretty great :)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9750d0d-62aa-4c47-a63e-5755aa8b05d7",
   "metadata": {},
   "source": [
    "**We will use lemmitized processed column of the textual reviews:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4929b7a0-5f30-4806-8ab7-c111ef1161e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main= df[['lemmitized', 'sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55314465-3340-4adc-a019-cd950ea421d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemmitized</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one reviewer mentioned watching 1 oz episode y...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wonderful little production filming technique ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>thought wonderful way spend time hot summer we...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically there family little boy jake think t...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter matteis love time money visually stunni...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          lemmitized sentiment\n",
       "0  one reviewer mentioned watching 1 oz episode y...  positive\n",
       "1  wonderful little production filming technique ...  positive\n",
       "2  thought wonderful way spend time hot summer we...  positive\n",
       "3  basically there family little boy jake think t...  negative\n",
       "4  petter matteis love time money visually stunni...  positive"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_main.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a27b64e-5f79-4a2a-a497-20d1a1d4f54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#covnerting to text and label form\n",
    "x = df_main.iloc[:,0:1]\n",
    "y = df['sentiment']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "93e48d50-2dbc-4ce2-9489-7b76df663ac1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemmitized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one reviewer mentioned watching 1 oz episode y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wonderful little production filming technique ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>thought wonderful way spend time hot summer we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically there family little boy jake think t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter matteis love time money visually stunni...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          lemmitized\n",
       "0  one reviewer mentioned watching 1 oz episode y...\n",
       "1  wonderful little production filming technique ...\n",
       "2  thought wonderful way spend time hot summer we...\n",
       "3  basically there family little boy jake think t...\n",
       "4  petter matteis love time money visually stunni..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "26236113-9cd5-4706-90af-0032a9ff58fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        positive\n",
       "1        positive\n",
       "2        positive\n",
       "3        negative\n",
       "4        positive\n",
       "           ...   \n",
       "49995    positive\n",
       "49996    negative\n",
       "49997    negative\n",
       "49998    negative\n",
       "49999    negative\n",
       "Name: sentiment, Length: 49578, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1bc800b-af75-455f-badb-62b5b0962d0e",
   "metadata": {},
   "source": [
    "**Encoding the Labels of the Reviews:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ccb2934c-57ea-454b-9532-d94cb0633e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "y = encoder.fit_transform(y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d5a56891-e9cf-4bac-b074-bac33974540c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48f04c5-256e-4d31-b8fe-4426cf4b994b",
   "metadata": {},
   "source": [
    "Representing Positive with 1 and Negative with 0 in above encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05cf08ae-8cda-401f-b826-d882eef69f3b",
   "metadata": {},
   "source": [
    "**Splitting the Dataset into Train-Test:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "41853fee-efe9-4411-91d2-842ed2dd6db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1262207e-2676-4a03-aa56-43a05f2d03eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39662, 1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e605a8-b957-4cff-a323-8a0e8a6cb128",
   "metadata": {},
   "source": [
    "## Feature Extraction:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10aa0fb-5e42-492c-8579-4806d43c029e",
   "metadata": {},
   "source": [
    "We will use Bag of Words technique for the Feature Extraction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a469c77f-458a-494d-bf8c-625273ef51e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "#for all the vocabulary it is not able to make the array due to memory allocation error so we have to use top 10000 vocabulary (unique words)\n",
    "cv = CountVectorizer(max_features=10000)\n",
    "X_train_bow = cv.fit_transform(X_train['lemmitized']).toarray()\n",
    "X_test_bow = cv.transform(X_test['lemmitized']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9db4fd28-8cab-47f1-942c-7ba81a325514",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39662, 10000)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_bow.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d4438e-6d89-4ad6-bcee-e83d0e168606",
   "metadata": {},
   "source": [
    "## Machine Learning Modelling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "29ac6e3e-3a64-4492-844f-ffa8945d8422",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8425776522791448"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "rf.fit(X_train_bow,y_train)\n",
    "y_pred = rf.predict(X_test_bow)\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "28f02217-7f82-4e88-b135-92bbfa7340f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4152,  763],\n",
       "       [ 798, 4203]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0452cfe3-e00c-4641-ba23-c863833167fb",
   "metadata": {},
   "source": [
    "**Using ngram Techinuq for the Feature Extraction Part:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f0511eeb-b350-4529-b254-b1cd30f16250",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8520572811617588"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = CountVectorizer(ngram_range=(1,3),max_features=10000)\n",
    "\n",
    "X_train_bow = cv.fit_transform(X_train['lemmitized']).toarray()\n",
    "X_test_bow = cv.transform(X_test['lemmitized']).toarray()\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "rf.fit(X_train_bow,y_train)\n",
    "y_pred = rf.predict(X_test_bow)\n",
    "accuracy_score(y_test,y_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41aa333-8712-418b-9935-7cd2c8500026",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
